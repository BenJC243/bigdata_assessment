{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55934b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading relevant modules \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model, preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import feature_selection#, metrics\n",
    "from sklearn.feature_selection import RFE \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5533edd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame shape (101766, 50) \n",
      " \n",
      "Dropping column repaglinide\n",
      "Dropping column nateglinide\n",
      "Dropping column chlorpropamide\n",
      "Dropping column acetohexamide\n",
      "Dropping column tolbutamide\n",
      "Dropping column acarbose\n",
      "Dropping column miglitol\n",
      "Dropping column troglitazone\n",
      "Dropping column tolazamide\n",
      "Dropping column examide\n",
      "Dropping column citoglipton\n",
      "Dropping column glyburide-metformin\n",
      "Dropping column glipizide-metformin\n",
      "Dropping column glimepiride-pioglitazone\n",
      "Dropping column metformin-rosiglitazone\n",
      "Dropping column metformin-pioglitazone\n",
      "\n",
      "\n",
      "Numerical columns are: ['patient_nbr', 'admission_source_id', 'time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'number_diagnoses'] \n",
      "\n",
      "Categorical columns are: ['race', 'gender', 'age', 'payer_code', 'medical_specialty', 'diag_1', 'diag_2', 'diag_3', 'max_glu_serum', 'A1Cresult', 'metformin', 'glimepiride', 'glipizide', 'glyburide', 'pioglitazone', 'rosiglitazone', 'insulin', 'change', 'diabetesMed', 'readmitted', 'admission_type_id', 'encounter_id', 'discharge_disposition_id'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Importing the data \n",
    "df = pd.read_csv(\"diabetic_data.csv\")\n",
    "\n",
    "\n",
    "#The shape of the dataframe \n",
    "print(f\"Initial DataFrame shape {df.shape} \\n \") \n",
    "\n",
    "#Replace all missing values\n",
    "df.replace('?',np.nan,inplace=True) #Replace ? with NaN \n",
    "df.replace(r'^\\s*$', np.nan, regex=True, inplace=True) #Replace empty space with NaN\n",
    "\n",
    "min50= float(0.5*(df.shape[0]+1)) #create object with value of 50% row total\n",
    "df= df.dropna(axis=1,thresh=min50) #drop columns with values missing from 50% of rows \n",
    "df.dropna(axis=0,how='any') #drop any rows with missing values \n",
    "\n",
    "#drop columns with 95% same values \n",
    "col_heads=df.columns\n",
    "df['age'].value_counts(dropna=False) #returns each value with list of counts \n",
    "min95=float(0.95*(df.shape[0]+1)) #determine 95% of values \n",
    "for column in col_heads: #for each column in col_heads \n",
    "    mylist= df[column].value_counts(dropna=False) #make a list of counts for each value found in the column\n",
    "    for x in mylist: #for each value (count no. of each value in col)\n",
    "        if x >= min95: #if the value is present in 95% of rows \n",
    "            df.drop(axis=1,columns=column,inplace=True)\n",
    "            statement= 'dropping column: {}'.format(column)\n",
    "            print(f\"Dropping column {column}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "#Drop rows with missing values \n",
    "df.dropna(how='any', inplace=True) \n",
    "\n",
    "#Shape of dataframe after column removal \n",
    "#print(df.shape)\n",
    "\n",
    "#Transforming the age column to the middle value\n",
    "def age_midpoint(df):\n",
    "    f = df['age'].str.split(pat='-')\n",
    "    ls = []\n",
    "    for i in f:\n",
    "        x = i[0][1]\n",
    "        d = str(x[0]) + str(5)\n",
    "        ls.append(d)\n",
    "    n = df.columns[5]\n",
    "    df.drop(n, axis = 1, inplace = True)\n",
    "    df[n] = ls\n",
    "    df['age'] = df[n]\n",
    "    return df['age']\n",
    "\n",
    "df['age'] = age_midpoint(df)\n",
    "\n",
    "\n",
    "#Replacing missing values in columns diag_1/2/3 \n",
    "df[\"diag_1\"].fillna(0, inplace=True)\n",
    "df[\"diag_2\"].fillna(0, inplace=True)\n",
    "df[\"diag_3\"].fillna(0, inplace=True)\n",
    "\n",
    "#List of numerical and categorical features  \n",
    "col_heads=df.columns\n",
    "catlist= df.select_dtypes(object).columns.values.tolist()\n",
    "numlist= df.select_dtypes(np.number).columns.values.tolist()\n",
    "\n",
    "for col in numlist:\n",
    "    if col[-2:]=='id':\n",
    "        numlist.remove(col)\n",
    "        catlist.append(col)\n",
    "\n",
    "print(f'Numerical columns are: {numlist} \\n')  \n",
    "\n",
    "print(f'Categorical columns are: {catlist} \\n')\n",
    "\n",
    " \n",
    "\n",
    "def identify_outlier(df):\n",
    "    temp = np.zeros(df.shape[0])\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == int or df[col].dtype == float: #and not (('encounter_id') or ('patient_nbr')):\n",
    "            if df[col] is not df['encounter_id'] and (df[col] is not df['patient_nbr']):\n",
    "                for i, x in enumerate(df[col]):\n",
    "                    mu = df[col].mean()\n",
    "                    dist_from_mean = abs(x - mu)\n",
    "                    dev = df[col].std()\n",
    "                    y= 3*dev\n",
    "                    if (dist_from_mean > y): #if larger than 3 std devs away from mu, mark as outlier\n",
    "                        temp[i] = 1\n",
    "\n",
    "    df['outliers'] = temp\n",
    "    return df\n",
    "\n",
    "df = identify_outlier(df)\n",
    "\n",
    "# Removing outliers\n",
    "def removed_outliers(df, outliers=True):\n",
    "    if outliers:\n",
    "        df = identify_outlier(df)  # mark outliers\n",
    "        df = df[df['outliers'] == 0].copy() # filter for outliers\n",
    "        df.drop('outliers', axis = 1, inplace = True)\n",
    "    return df\n",
    "df = removed_outliers(df, outliers=True)\n",
    "   \n",
    "\n",
    "#Removing duplicates in the column patient_nbr \n",
    "df = df.drop_duplicates(subset='patient_nbr',keep='first')\n",
    "\n",
    "print(f\"Final DataFrame shape {df.shape}\")\n",
    "\n",
    "\n",
    "'''Data Exploration'''\n",
    "#Grouping ICD code description by the type of clinical diagnoses\n",
    "ls = list(df['diag_1'])\n",
    "\n",
    "#Three functions to link the ICD codes found in the columns diag_1/2/3 to diagnosing\n",
    "def diag_1(df):\n",
    "    for i, x in enumerate(df['diag_1']):\n",
    "        v = str(x)\n",
    "        if v[0].isalpha():\n",
    "            ls[i] = v.replace(v,'other')\n",
    "        elif v[0].isdigit():\n",
    "            s = float(v)\n",
    "            if (s > 390 and s < 460) or s == 785:#s in range(390, 460):\n",
    "                p = str(s)\n",
    "                #assimialtes values 390,460 with circulatory disease, repeated for the different clinical diagnoses\n",
    "                ls[i] = p.replace(p,'circulatory_disease') \n",
    "            elif s > 249.99 and s < 251:\n",
    "                p = str(s)\n",
    "                ls[i] = p.replace(p,'diabetes_mellitus')\n",
    "            elif (s > 459 and s < 520) or s == 786:\n",
    "                p = str(s)\n",
    "                ls[i] = p.replace(p,'respiratory_disease')\n",
    "            elif (s > 519 and s < 580) or s == 787:\n",
    "                p = str(s)\n",
    "                ls[i] = p.replace(p,'gastrointestinal_disease')\n",
    "            elif (s > 799 and s < 1000):\n",
    "                p = str(s)\n",
    "                ls[i] = p.replace(p,'injury/poisoning')\n",
    "            elif (s > 709 and s < 740):\n",
    "                p = str(s)\n",
    "                ls[i] = p.replace(p,'musculoskeletal/connective')\n",
    "            elif (s > 579 and s < 740):\n",
    "                p = str(s)\n",
    "                ls[i] = p.replace(p,'genitourinary')\n",
    "            elif (s > 139 and s < 240):\n",
    "                p = str(s)\n",
    "                ls[i] = p.replace(p,'neoplasms')\n",
    "            else:\n",
    "                p = str(s)\n",
    "                ls[i] = p.replace(p,'other')                \n",
    "\n",
    "    df['diag_1'] = ls\n",
    "    return df['diag_1']\n",
    "\n",
    "df['diag_1'] = diag_1(df)\n",
    "\n",
    "ls1 = list(df['diag_2'])\n",
    "def diag_2(df):\n",
    "    for i, x in enumerate(df['diag_2']):\n",
    "        v = str(x)\n",
    "        if v[0].isalpha():\n",
    "            ls1[i] = v.replace(v,'other')\n",
    "        elif v[0].isdigit():\n",
    "            s = float(v)\n",
    "            if (s > 390 and s < 460) or s == 785:#s in range(390, 460):\n",
    "                p = str(s)\n",
    "                ls1[i] = p.replace(p,'circulatory_disease')\n",
    "            elif s > 249.99 and s < 251:\n",
    "                p = str(s)\n",
    "                ls[i] = p.replace(p,'diabetes_mellitus')\n",
    "            elif (s > 459 and s < 520) or s == 786:\n",
    "                p = str(s)\n",
    "                ls1[i] = p.replace(p,'respiratory_disease')\n",
    "            elif (s > 519 and s < 580) or s == 787:\n",
    "                p = str(s)\n",
    "                ls1[i] = p.replace(p,'gastrointestinal_disease')\n",
    "            elif (s > 799 and s < 1000):\n",
    "                p = str(s)\n",
    "                ls1[i] = p.replace(p,'injury/poisoning')\n",
    "            elif (s > 709 and s < 740):\n",
    "                p = str(s)\n",
    "                ls1[i] = p.replace(p,'musculoskeletal/connective')\n",
    "            elif (s > 579 and s < 740):\n",
    "                p = str(s)\n",
    "                ls1[i] = p.replace(p,'genitourinary')\n",
    "            elif (s > 139 and s < 240):\n",
    "                p = str(s)\n",
    "                ls1[i] = p.replace(p,'neoplasms')\n",
    "            else:\n",
    "                p = str(s)\n",
    "                ls1[i] = p.replace(p,'other')                \n",
    "\n",
    "    df['diag_2'] = ls\n",
    "    return df['diag_2']\n",
    "\n",
    "df['diag_2'] = diag_2(df)\n",
    "\n",
    "ls2 = list(df['diag_3'])\n",
    "def diag_3(df):\n",
    "    for i, x in enumerate(df['diag_3']):\n",
    "        v = str(x)\n",
    "        if v[0].isalpha():\n",
    "            ls1[i] = v.replace(v,'other')\n",
    "        elif v[0].isdigit():\n",
    "            s = float(v)\n",
    "            if (s > 390 and s < 460) or s == 785:#s in range(390, 460):\n",
    "                p = str(s)\n",
    "                ls2[i] = p.replace(p,'circulatory_disease')\n",
    "            elif s > 249.99 and s < 251:\n",
    "                p = str(s)\n",
    "                ls2[i] = p.replace(p,'diabetes_mellitus')\n",
    "            elif (s > 459 and s < 520) or s == 786:\n",
    "                p = str(s)\n",
    "                ls2[i] = p.replace(p,'respiratory_disease')\n",
    "            elif (s > 519 and s < 580) or s == 787:\n",
    "                p = str(s)\n",
    "                ls2[i] = p.replace(p,'gastrointestinal_disease')\n",
    "            elif (s > 799 and s < 1000):\n",
    "                p = str(s)\n",
    "                ls2[i] = p.replace(p,'injury/poisoning')\n",
    "            elif (s > 709 and s < 740):\n",
    "                p = str(s)\n",
    "                ls2[i] = p.replace(p,'musculoskeletal/connective')\n",
    "            elif (s > 579 and s < 740):\n",
    "                p = str(s)\n",
    "                ls2[i] = p.replace(p,'genitourinary')\n",
    "            elif (s > 139 and s < 240):\n",
    "                p = str(s)\n",
    "                ls2[i] = p.replace(p,'neoplasms')\n",
    "            else:\n",
    "                p = str(s)\n",
    "                ls2[i] = p.replace(p,'other')                \n",
    "\n",
    "    df['diag_3'] = ls\n",
    "    return df['diag_3']\n",
    "df['diag_3'] = diag_3(df)\n",
    "\n",
    "\n",
    "#Function that shows histograms of patietns readmiteted based on age\n",
    "def readmission_hists(df, plot_cols, grid_col):\n",
    "    for col in plot_cols:\n",
    "        if col == 'age':\n",
    "            g = sns.FacetGrid(df, col=grid_col, margin_titles=True)\n",
    "            g.map(plt.hist, col)\n",
    "            plt.show()\n",
    "readmission_hists(df, df.select_dtypes(include=[np.number]).columns, \"readmitted\")\n",
    "\n",
    "\n",
    "#Calculation of the number of men/women and people of different race that were readmitted \n",
    "ls3=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['gender_Male'])):\n",
    "    if int(i) == int(j):\n",
    "        ls3.append(i)\n",
    "print(ls3.count('1'), 'male') # = num of men readmitted\n",
    "\n",
    "\n",
    "ls4=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['gender_Female'])):\n",
    "    if int(i) == int(j):\n",
    "        ls4.append(i)\n",
    "print(ls4.count('1'), 'female')\n",
    "\n",
    "ls5=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['race_Caucasian'])):\n",
    "    if int(i) == int(j):\n",
    "        ls5.append(i)\n",
    "print(ls5.count('1'), 'cauc')\n",
    "\n",
    "ls6=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['race_AfricanAmerican'])):\n",
    "    if int(i) == int(j):\n",
    "        ls6.append(i)\n",
    "print(ls6.count('1'), 'african-americ')\n",
    "\n",
    "ls7=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['race_Asian'])):\n",
    "    if int(i) == int(j):\n",
    "        ls7.append(i)\n",
    "print(ls7.count('1'), 'asian')\n",
    "\n",
    "ls8=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['race_Hispanic'])):\n",
    "    if int(i) == int(j):\n",
    "        ls8.append(i)\n",
    "print(ls8.count('1'), 'hispanic')\n",
    "\n",
    "print(df['gender_Male'].value_counts())\n",
    "print(df['gender_Female'].value_counts())\n",
    "print(df['race_Caucasian'].value_counts())\n",
    "print(df['race_AfricanAmerican'].value_counts())\n",
    "print(df['race_Asian'].value_counts())\n",
    "print(df['race_Hispanic'].value_counts())\n",
    "\n",
    "#normalised --> (total of group that were readmitted)/(total of group)\n",
    "x = ['Male', 'Female']\n",
    "y = [11410 / 30191, 13450 / 34274]\n",
    "sns.barplot(x, y).set_title(\"Gender vs Readmission\")\n",
    "plt.xlabel(\"Gender\")\n",
    "plt.ylabel(\"Percentage of patients readmitted / total group\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "x = ['Caucasian', 'African-American','Asian','Hispanic']\n",
    "y = [18997/48048, 4397/11718, 140/461, 449/1341]\n",
    "\n",
    "sns.barplot(x, y).set_title(\"Ethnicity vs Readmission\")\n",
    "plt.xlabel(\"Race\")\n",
    "plt.ylabel(\"Percentage Readmission\")\n",
    "plt.show()\n",
    "\n",
    "ls9=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['diag_1'])):\n",
    "    if i == '1' and j == 'circulatory_disease':\n",
    "        ls9.append(1)\n",
    "print(ls9.count(1), 'circulatory')\n",
    "\n",
    "ls9=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['diag_1'])):\n",
    "    if i == '1' and j == 'respiratory_disease':\n",
    "        ls9.append(1)\n",
    "print(ls9.count(1), 'respiratory')\n",
    "\n",
    "ls9=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['diag_1'])):\n",
    "    if i == '1' and j == 'gastrointestinal_disease':\n",
    "        ls9.append(1)\n",
    "print(ls9.count(1), 'gastrointestinal_disease')\n",
    "\n",
    "ls9=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['diag_1'])):\n",
    "    if i == '1' and j == 'genitourinary':\n",
    "        ls9.append(1)\n",
    "print(ls9.count(1), 'genitourinary')\n",
    "\n",
    "ls9=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['diag_1'])):\n",
    "    if i == '1' and j == 'diabetes_mellitus':\n",
    "        ls9.append(1)\n",
    "print(ls9.count(1), 'diabetes_mellitus')\n",
    "\n",
    "ls9=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['diag_1'])):\n",
    "    if i == '1' and j == 'musculoskeletal/connective':\n",
    "        ls9.append(1)\n",
    "print(ls9.count(1), 'musculoskeletal/connective')\n",
    "\n",
    "ls9=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['diag_1'])):\n",
    "    if i == '1' and j == 'injury/poisoning':\n",
    "        ls9.append(1)\n",
    "print(ls9.count(1), 'injury/poisoning')\n",
    "        \n",
    "ls9=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['diag_1'])):\n",
    "    if i == '1' and j == 'neoplasms':\n",
    "        ls9.append(1)\n",
    "print(ls9.count(1), 'neoplasms')\n",
    "\n",
    "ls9=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['diag_1'])):\n",
    "    if i == '1' and j == 'other':\n",
    "        ls9.append(1)\n",
    "print(ls9.count(1), 'other')\n",
    "\n",
    "\n",
    "\n",
    "df['diag_1'].value_counts()\n",
    "\n",
    "\n",
    "x = ['Circulatory', 'Respiratory', 'Gastrointestinal','Genitourinary','Diabetes',\n",
    "    'musculoskeletal/connective', 'injury/poisoning', 'Neoplasms', 'other']\n",
    "y = [8025/19652, 3581/9006, 2274/6077, 1926/5345, 1959/4690, 1319/3847, 1603/4361, 755/2544, 3418/8946]\n",
    "\n",
    "#We initailly inteded to use this graph but upon further review we decided in selecting the next graph \n",
    "ax = sns.set(rc={'figure.figsize':(20,7.5)})\n",
    "sns.barplot(x, y,).set_title(\"Readmisson rates males vs females\")\n",
    "plt.xlabel(\"Clincal Diagnoses\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "ls11=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['diag_2'])):\n",
    "    if i == '1' and j == 'circulatory_disease':\n",
    "        ls11.append(1)\n",
    "print(ls11.count(1), 'circulatory')\n",
    "\n",
    "ls11=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['diag_2'])):\n",
    "    if i == '1' and j == 'respiratory_disease':\n",
    "        ls11.append(1)\n",
    "print(ls11.count(1), 'respiratory')\n",
    "\n",
    "ls11=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['diag_2'])):\n",
    "    if i == '1' and j == 'gastrointestinal_disease':\n",
    "        ls11.append(1)\n",
    "print(ls11.count(1), 'gastrointestinal_disease')\n",
    "\n",
    "ls11=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['diag_2'])):\n",
    "    if i == '1' and j == 'genitourinary':\n",
    "        ls11.append(1)\n",
    "print(ls11.count(1), 'genitourinary')\n",
    "\n",
    "ls11=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['diag_2'])):\n",
    "    if i == '1' and j == 'diabetes_mellitus':\n",
    "        ls11.append(1)\n",
    "print(ls11.count(1), 'diabetes_mellitus')\n",
    "\n",
    "ls11=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['diag_2'])):\n",
    "    if i == '1' and j == 'musculoskeletal/connective':\n",
    "        ls11.append(1)\n",
    "print(ls11.count(1), 'musculoskeletal/connective')\n",
    "\n",
    "ls11=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['diag_2'])):\n",
    "    if i == '1' and j == 'injury/poisoning':\n",
    "        ls11.append(1)\n",
    "print(ls11.count(1), 'injury/poisoning')\n",
    "        \n",
    "ls11=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['diag_2'])):\n",
    "    if i == '1' and j == 'neoplasms':\n",
    "        ls11.append(1)\n",
    "print(ls11.count(1), 'neoplasms')\n",
    "\n",
    "ls11=[]\n",
    "for i, j in zip(list(df['readmitted']), list(df['diag_2'])):\n",
    "    if i == '1' and j == 'other':\n",
    "        ls11.append(1)\n",
    "print(ls11.count(1), 'other')\n",
    "\n",
    "print(df['diag_2'].value_counts())\n",
    "\n",
    "#Improved plot\n",
    "#DIAG 2 & 3 (same num of diagnoses)\n",
    "x = ['Circulatory disease', 'Respiratory disease', 'Gastrointestinal disease','Genitourinary disease','Diabetes',\n",
    "    'musculoskeletal/connective', 'injury/poisoning', 'neoplasms', 'other']\n",
    "y = [7012/17205, 3047/7504, 1937/5137, 1561/4254, 5247/13691, 1031/2941, 0, 679/2241, 2928/7625]\n",
    "\n",
    "sns.set(rc={'figure.figsize':(20,7.5)})\n",
    "sns.barplot(x, y).set_title(\"Percentage Readmission based on Clinical Diagnoses\")\n",
    "plt.xlabel(\"Clinical Diagnoses\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "'''Model Building'''\n",
    "\n",
    "#df = df.loc[:,~df.columns.duplicated()] #remove duplicated 'readmitted' col\n",
    "df1 = df[['encounter_id','num_medications', 'number_outpatient', 'number_emergency', 'time_in_hospital', \n",
    "'number_inpatient', 'age', 'num_lab_procedures', 'number_diagnoses', \n",
    "'num_procedures','diag_1', 'diag_2', 'diag_3', 'readmitted']]\n",
    "df1 = df1.drop(df1.loc[df1['diag_1']!='diabetes_mellitus'].index)#, inplace=False)\n",
    "df1 = df1.drop(df1.loc[df1['diag_2']!='diabetes_mellitus'].index)#, inplace=False)\n",
    "df1 = df1.drop(df1.loc[df1['diag_3']!='diabetes_mellitus'].index)#, inplace=False)\n",
    "\n",
    "model1 = linear_model.LogisticRegression()\n",
    "cols = ['num_medications', 'number_outpatient', 'number_emergency', 'time_in_hospital', \n",
    "'number_inpatient', 'age', 'num_lab_procedures', 'number_diagnoses', 'num_procedures', 'encounter_id']\n",
    "\n",
    "X = df1[cols]\n",
    "Y = df1['readmitted']\n",
    "model1.fit(X, Y)\n",
    "\n",
    "print('Model score:\\n ', model1.score(X,Y))\n",
    "print('Coefficients: ')\n",
    "for feat, coef in zip(cols, model1.coef_[0]):\n",
    "    print(feat, coef)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "X, Y, test_size=0.25)\n",
    "model2 = linear_model.LogisticRegression()\n",
    "model2.fit(X_train, Y_train)\n",
    "print(\"Score against training data: \",model2.score(X_train, Y_train))\n",
    "print(\"Score against test data: \", model2.score(X_test, Y_test))\n",
    "#scores = cross_val_score(linear_model.LogisticRegression(), X, Y, scoring='accuracy', cv=10)\n",
    "#print(\"Cross validation mean scores: {}\".format(scores.mean()))\n",
    "\n",
    "#CONFUSION MATRIX\n",
    "\n",
    "df1['readmitted'] = df1['readmitted'].replace({1:'1', 1:'1', 0: '0'})\n",
    "#df1['readmitted'] = df1['readmitted'].replace({'1':1, '0':0})\n",
    "\n",
    "\n",
    "pred_test = model2.predict(X_test)\n",
    "pred_train = model2.predict(X_train)\n",
    "\n",
    "## Acuracy score for the training data\n",
    "accuracy_train = accuracy_score(pred_train, Y_train)\n",
    "print('Accuracy for the training set: ', accuracy_train)\n",
    "## Acuracy score for the test data\n",
    "accuracy_test = accuracy_score(pred_test, Y_test)\n",
    "print('Accuracy for the test set: ', accuracy_test)\n",
    "\n",
    "\n",
    "# confusion matrix for the test data\n",
    "pred = pred_test\n",
    "cm = confusion_matrix(Y_test, pred)\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(Y_test, pred_test).ravel()\n",
    "\n",
    "print('True Positives: ', TP)\n",
    "print('False Positives: ', FP)\n",
    "print('True Negatives: ', TN)\n",
    "print('False Negatives: ', FN)\n",
    "\n",
    "accuracy = (TP+TN) /(TP+FP+TN+FN)\n",
    "\n",
    "print('Accuracy score = ', accuracy)\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=model2.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "# Calculate Accuracy, Precision and Recall Metrics for the test data\n",
    "accuracy = accuracy_score(pred, Y_test)\n",
    "print('Accuracy: ', accuracy)\n",
    "precision = precision_score(pred, Y_test,pos_label = '1')\n",
    "print('Precision: ', precision)\n",
    "recall = recall_score(pred, Y_test,pos_label = '1')\n",
    "print('Recall: ', recall)\n",
    "f1score = f1_score(pred, Y_test,pos_label = '1')\n",
    "\n",
    "print('F1_score: ', f1score)\n",
    "plt.show()\n",
    "\n",
    "   #CROSS VALIDATION\n",
    "scores = cross_val_score(linear_model.LogisticRegression(), X, Y, scoring='accuracy')\n",
    "print('Cross validation mean score: ', scores.mean())\n",
    "\n",
    "#Improved model\n",
    "\n",
    "#df = df.loc[:,~df.columns.duplicated()] #remove duplicated 'readmitted' col\n",
    "df1 = df[['num_medications', 'number_outpatient', 'number_emergency', 'time_in_hospital', \n",
    "'number_inpatient', 'age', 'num_lab_procedures', 'number_diagnoses', \n",
    "'num_procedures','diag_1', 'diag_2', 'diag_3', 'readmitted']]\n",
    "df1 = df1.drop(df1.loc[df1['diag_1']!='diabetes_mellitus'].index)\n",
    "df1 = df1.drop(df1.loc[df1['diag_2']!='diabetes_mellitus'].index)\n",
    "df1 = df1.drop(df1.loc[df1['diag_3']!='diabetes_mellitus'].index)\n",
    "\n",
    "model1 = linear_model.LogisticRegression()\n",
    "cols = ['num_medications', 'number_outpatient', 'number_emergency', 'time_in_hospital', \n",
    "'number_inpatient', 'age', 'num_lab_procedures', 'number_diagnoses', 'num_procedures']\n",
    "\n",
    "X = df1[cols]\n",
    "Y = df1['readmitted']\n",
    "model1.fit(X, Y)\n",
    "\n",
    "print('Model score:\\n ', model1.score(X,Y))\n",
    "print('Coefficients: ')\n",
    "for feat, coef in zip(cols, model1.coef_[0]):\n",
    "    print(feat, coef)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "X, Y, test_size=0.25)\n",
    "model2 = linear_model.LogisticRegression()\n",
    "model2.fit(X_train, Y_train)\n",
    "print(\"Score against training data: \",model2.score(X_train, Y_train))\n",
    "print(\"Score against test data: \", model2.score(X_test, Y_test))\n",
    "#scores = cross_val_score(linear_model.LogisticRegression(), X, Y, scoring='accuracy', cv=10)\n",
    "#print(\"Cross validation mean scores: {}\".format(scores.mean()))\n",
    "\n",
    "#CONFUSION MATRIX\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n",
    "\n",
    "df1['readmitted'] = df1['readmitted'].replace({1:'1', 1:'1', 0: '0'})\n",
    "#df1['readmitted'] = df1['readmitted'].replace({'1':1, '0':0})\n",
    "\n",
    "#print(df1)\n",
    "#print(df['readmitted'])#.dtype)\n",
    "pred_test = model2.predict(X_test)\n",
    "pred_train = model2.predict(X_train)\n",
    "\n",
    "## Acuracy score for the training data\n",
    "accuracy_train = accuracy_score(pred_train, Y_train)\n",
    "print('Accuracy for the training set: ', accuracy_train)\n",
    "## Acuracy score for the test data\n",
    "accuracy_test = accuracy_score(pred_test, Y_test)\n",
    "print('Accuracy for the test set: ', accuracy_test)\n",
    "\n",
    "\n",
    "# confusion matrix for the test data\n",
    "pred = pred_test\n",
    "cm = confusion_matrix(Y_test, pred)\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(Y_test, pred_test).ravel()\n",
    "\n",
    "print('True Positives: ', TP)\n",
    "print('False Positives: ', FP)\n",
    "print('True Negatives: ', TN)\n",
    "print('False Negatives: ', FN)\n",
    "\n",
    "accuracy = (TP+TN) /(TP+FP+TN+FN)\n",
    "\n",
    "print('Accuracy score = ', accuracy)\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=model2.classes_).set_title(\"Confusion Matrix\")\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "# Calculate Accuracy, Precision and Recall Metrics for the test data\n",
    "accuracy = accuracy_score(pred, Y_test)\n",
    "print('Accuracy: ', accuracy)\n",
    "precision = precision_score(pred, Y_test,pos_label = '1')\n",
    "print('Precision: ', precision)\n",
    "recall = recall_score(pred, Y_test,pos_label = '1')\n",
    "print('Recall: ', recall)\n",
    "f1score = f1_score(pred, Y_test,pos_label = '1')\n",
    "\n",
    "print('F1_score: ', f1score)\n",
    "plt.show()\n",
    "\n",
    "   #CROSS VALIDATION\n",
    "scores = cross_val_score(linear_model.LogisticRegression(), X, Y, scoring='accuracy')\n",
    "print('Cross validation mean score: ', scores.mean())\n",
    "\n",
    "\n",
    "'''K Means Clustering'''\n",
    "#create object w/ numerical column list \n",
    "col_heads=list(df.columns)\n",
    "catlist= df.select_dtypes(object).columns.values.tolist()\n",
    "numlist= df.select_dtypes(np.number).columns.values.tolist()\n",
    "\n",
    "for col in numlist:\n",
    "    if col != 'encounter_id'and col[-2:] =='id':\n",
    "        numlist.remove(col)\n",
    "        catlist.append(col)\n",
    "numlist.remove('patient_nbr')\n",
    "\n",
    "#min/max normalisations and dropping non-continuous variables from data frame \n",
    "df_norm=df.copy()\n",
    "for x in numlist: \n",
    "    if x in df.columns:\n",
    "        df_norm[x]= (df[x]-df[x].min()) / (df[x].max()-df[x].min())\n",
    "df_norm.loc[1]\n",
    "\n",
    "#remove categorical values from df, and also patient numbers/ids \n",
    "for x in catlist:\n",
    "    if x in df_norm.columns:\n",
    "        df_norm.drop(labels=x,axis=1, inplace=True)\n",
    "df_norm.drop(labels=['patient_nbr','admission_source_id'],axis=1,inplace=True)\n",
    "\n",
    "### model building \n",
    "#call algorithm with 6 clusters \n",
    "model = KMeans(n_clusters=6)\n",
    "model.fit(df_norm)\n",
    "print('cost=',model.inertia_) # J score (lower = better)\n",
    "#j score = sum of square distances between each point + its centroid \n",
    "print(model.labels_) #labels denoting clusters for each row of df \n",
    "\n",
    "#add cluster assignments to df with below script \n",
    "labels=model.labels_ #take titles of each labelled datapoint \n",
    "md=pd.Series(labels) #make a series out of each datapoint \n",
    "df['clust']=md\n",
    "df_norm['clust']=md\n",
    "# means of data points for each cluster \n",
    "df_norm.groupby('clust').mean()\n",
    "# see the mean of each column for each cluster \n",
    "\n",
    "#make elbow plot - for determining / supporting K value\n",
    "#identify 'joint' in elbow that informs on optimal cluster no. \n",
    "def elbow(data):\n",
    "    print(\"\\nPlotting elbow method...\")\n",
    "    sse = {}\n",
    "    for k in range(2, 20, 2):\n",
    "        kmeans = KMeans(n_clusters=k, max_iter=1000).fit(data)\n",
    "        print(k, kmeans.inertia_)\n",
    "        sse[k] = kmeans.inertia_  \n",
    "        # Inertia: Sum of distances of samples to their closest cluster center\n",
    "    plt.figure()\n",
    "    plt.plot(list(sse.keys()), list(sse.values()), linewidth=4)\n",
    "    plt.xlabel(\"Number of clusters\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    print(\"DONE\")\n",
    "elbow(df_norm) # use the above function to print an elbow plot for our data \n",
    "\n",
    "##PCA \n",
    "######## 2D plot of the clusters\n",
    "##create PCA model \n",
    "pca_data = PCA(n_components=2).fit(df_norm)\n",
    "pca_2d = pca_data.transform(df_norm)\n",
    "\n",
    "#create new column for readmission data to overlay on scatterplot \n",
    "df.readmitted=pd.Categorical(df.readmitted) #create category of readmittance to colour the plot\n",
    "df['code'] = df.readmitted.cat.codes #0 = <30, 1 = >30, 2= NO\n",
    "\n",
    "#plot scatterplot of clusters using PCAs \n",
    "plt.scatter(pca_2d[:,0], pca_2d[:,1], c=labels) #change c= to labels/df['code'] for different colours of clusters \n",
    "#plt.legend([0,1,2],['Before 30d', 'After 30d','Not readmitted']) #0 = <30, 1 = >30, 2= NO\n",
    "plt.title('Patient clusters / all continuous variables / k = 6')\n",
    "plt.show()\n",
    "\n",
    "# second graph w/ readmitted status overlayed\n",
    "plt.scatter(pca_2d[:,0], pca_2d[:,1], c=df['code']) #change c= to labels/df['code'] for different colours of clusters \n",
    "#plt.legend([0,1,2],['Before 30d', 'After 30d','Not readmitted']) #0 = <30, 1 = >30, 2= NO\n",
    "plt.title('Patient clusters / all continuous variables / k = 6')\n",
    "plt.show()\n",
    "\n",
    "##IMPROVEMENTS TO THE K-MEANS MODEL (using PCA)\n",
    "df_norm.drop(labels=['encounter_id'],axis=1,inplace=True) #DROP THIS - explains vast majority of variance \n",
    "pca=PCA()\n",
    "pca.fit(df_norm)\n",
    "\n",
    "pca.explained_variance_ratio_ #show the amount of variance each column explains\n",
    "\n",
    "#cumulative variance plot to determine no. of features to include in PCA \n",
    "##CUMULATIVE VARIANCE PLOT \n",
    "plt.plot(range(1,10),pca.explained_variance_ratio_.cumsum(),marker='o',linestyle='--')\n",
    "plt.title('explained variance by components')\n",
    "plt.xlabel('no. of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "\n",
    "pca2 = PCA(n_components=5) #build new PCA model \n",
    "pca2.fit(df_norm) #fit our data to PCA model \n",
    "scores_pca2=pca2.transform(df_norm) #list scores from model \n",
    "\n",
    "#calling values from new model \n",
    "newmodel=KMeans(n_clusters=8,init='k-means++',random_state=50) #create new KMeans model for PCA data \n",
    "newmodel.fit(scores_pca2)\n",
    "\n",
    "j=newmodel.inertia_ #get j-score for new model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c757d15c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
